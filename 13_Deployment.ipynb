{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "native-original",
   "metadata": {},
   "source": [
    "# 13 Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-credits",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "electric-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "packed-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=pd.read_csv('@Source/DATA/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "statistical-tradition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "based-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=iris.drop('species', axis=1)\n",
    "y=iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "domestic-course",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sacred-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "encoder=LabelBinarizer()\n",
    "y=encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "functioning-leadership",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accessory-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "scaled_X_train=scaler.fit_transform(X_train)\n",
    "scaled_X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedicated-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "marked-slide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 1s 10ms/sample - loss: 1.0987 - accuracy: 0.3500 - val_loss: 1.1252 - val_accuracy: 0.2667\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0963 - accuracy: 0.3500 - val_loss: 1.1224 - val_accuracy: 0.2667\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 1.0939 - accuracy: 0.3500 - val_loss: 1.1200 - val_accuracy: 0.2667\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0916 - accuracy: 0.3500 - val_loss: 1.1177 - val_accuracy: 0.2667\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 1.0895 - accuracy: 0.3500 - val_loss: 1.1152 - val_accuracy: 0.2667\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 1.0874 - accuracy: 0.3500 - val_loss: 1.1129 - val_accuracy: 0.2667\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 1.0852 - accuracy: 0.3500 - val_loss: 1.1108 - val_accuracy: 0.2667\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0832 - accuracy: 0.3500 - val_loss: 1.1087 - val_accuracy: 0.3000\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 1.0811 - accuracy: 0.3500 - val_loss: 1.1066 - val_accuracy: 0.3000\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 1.0791 - accuracy: 0.3500 - val_loss: 1.1045 - val_accuracy: 0.3000\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 1.0770 - accuracy: 0.3500 - val_loss: 1.1026 - val_accuracy: 0.3000\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 1.0750 - accuracy: 0.3500 - val_loss: 1.1006 - val_accuracy: 0.3000\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 1.0729 - accuracy: 0.3500 - val_loss: 1.0987 - val_accuracy: 0.3000\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0709 - accuracy: 0.3500 - val_loss: 1.0969 - val_accuracy: 0.3000\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0690 - accuracy: 0.3500 - val_loss: 1.0951 - val_accuracy: 0.3000\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 1.0669 - accuracy: 0.3500 - val_loss: 1.0931 - val_accuracy: 0.3000\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0649 - accuracy: 0.3500 - val_loss: 1.0914 - val_accuracy: 0.3000\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 1.0630 - accuracy: 0.3500 - val_loss: 1.0898 - val_accuracy: 0.3000\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0610 - accuracy: 0.3500 - val_loss: 1.0878 - val_accuracy: 0.3000\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0589 - accuracy: 0.3500 - val_loss: 1.0859 - val_accuracy: 0.3000\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0569 - accuracy: 0.3500 - val_loss: 1.0841 - val_accuracy: 0.3000\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 1.0549 - accuracy: 0.3500 - val_loss: 1.0823 - val_accuracy: 0.3000\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 1.0529 - accuracy: 0.3500 - val_loss: 1.0803 - val_accuracy: 0.3000\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 1.0509 - accuracy: 0.3500 - val_loss: 1.0785 - val_accuracy: 0.3000\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.0489 - accuracy: 0.3500 - val_loss: 1.0768 - val_accuracy: 0.3000\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 1.0468 - accuracy: 0.3500 - val_loss: 1.0749 - val_accuracy: 0.3000\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.0447 - accuracy: 0.3500 - val_loss: 1.0732 - val_accuracy: 0.3000\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 1.0427 - accuracy: 0.3500 - val_loss: 1.0715 - val_accuracy: 0.3000\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0406 - accuracy: 0.3583 - val_loss: 1.0697 - val_accuracy: 0.3000\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0385 - accuracy: 0.3667 - val_loss: 1.0676 - val_accuracy: 0.3000\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0364 - accuracy: 0.3750 - val_loss: 1.0658 - val_accuracy: 0.3000\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 1.0343 - accuracy: 0.3750 - val_loss: 1.0639 - val_accuracy: 0.3000\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 1.0322 - accuracy: 0.3833 - val_loss: 1.0619 - val_accuracy: 0.3000\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 1.0300 - accuracy: 0.3833 - val_loss: 1.0599 - val_accuracy: 0.3000\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 1.0279 - accuracy: 0.3833 - val_loss: 1.0580 - val_accuracy: 0.3667\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 1.0257 - accuracy: 0.3833 - val_loss: 1.0560 - val_accuracy: 0.3667\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 1.0236 - accuracy: 0.4000 - val_loss: 1.0543 - val_accuracy: 0.3667\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 1.0214 - accuracy: 0.4250 - val_loss: 1.0523 - val_accuracy: 0.3667\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 1.0192 - accuracy: 0.4417 - val_loss: 1.0505 - val_accuracy: 0.3667\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 1.0171 - accuracy: 0.4417 - val_loss: 1.0488 - val_accuracy: 0.3667\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 1.0148 - accuracy: 0.4583 - val_loss: 1.0468 - val_accuracy: 0.3667\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 1.0127 - accuracy: 0.4583 - val_loss: 1.0450 - val_accuracy: 0.4000\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 1.0105 - accuracy: 0.4667 - val_loss: 1.0432 - val_accuracy: 0.4000\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 1.0083 - accuracy: 0.4750 - val_loss: 1.0413 - val_accuracy: 0.4000\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 1.0061 - accuracy: 0.4833 - val_loss: 1.0392 - val_accuracy: 0.4000\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 1.0039 - accuracy: 0.5000 - val_loss: 1.0372 - val_accuracy: 0.4333\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 1.0016 - accuracy: 0.5000 - val_loss: 1.0352 - val_accuracy: 0.4333\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.9994 - accuracy: 0.5083 - val_loss: 1.0333 - val_accuracy: 0.4333\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.9972 - accuracy: 0.5250 - val_loss: 1.0314 - val_accuracy: 0.4333\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.9948 - accuracy: 0.5333 - val_loss: 1.0294 - val_accuracy: 0.4333\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.9925 - accuracy: 0.5500 - val_loss: 1.0275 - val_accuracy: 0.4333\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.9901 - accuracy: 0.5583 - val_loss: 1.0257 - val_accuracy: 0.4333\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.9877 - accuracy: 0.5833 - val_loss: 1.0237 - val_accuracy: 0.4667\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.9855 - accuracy: 0.5833 - val_loss: 1.0219 - val_accuracy: 0.4667\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9830 - accuracy: 0.5833 - val_loss: 1.0199 - val_accuracy: 0.4667\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 225us/sample - loss: 0.9807 - accuracy: 0.5917 - val_loss: 1.0179 - val_accuracy: 0.4667\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.9783 - accuracy: 0.6083 - val_loss: 1.0156 - val_accuracy: 0.4667\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.9759 - accuracy: 0.6083 - val_loss: 1.0137 - val_accuracy: 0.4667\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9735 - accuracy: 0.6250 - val_loss: 1.0116 - val_accuracy: 0.5000\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9711 - accuracy: 0.6250 - val_loss: 1.0094 - val_accuracy: 0.5000\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9688 - accuracy: 0.6250 - val_loss: 1.0074 - val_accuracy: 0.5000\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 177us/sample - loss: 0.9664 - accuracy: 0.6250 - val_loss: 1.0053 - val_accuracy: 0.5000\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.9639 - accuracy: 0.6250 - val_loss: 1.0031 - val_accuracy: 0.5333\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.9617 - accuracy: 0.6333 - val_loss: 1.0011 - val_accuracy: 0.5333\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.9592 - accuracy: 0.6333 - val_loss: 0.9990 - val_accuracy: 0.5333\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.9568 - accuracy: 0.6333 - val_loss: 0.9968 - val_accuracy: 0.5333\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 0.9544 - accuracy: 0.6500 - val_loss: 0.9946 - val_accuracy: 0.5333\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.9520 - accuracy: 0.6500 - val_loss: 0.9925 - val_accuracy: 0.5333\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 177us/sample - loss: 0.9496 - accuracy: 0.6500 - val_loss: 0.9902 - val_accuracy: 0.5333\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9472 - accuracy: 0.6583 - val_loss: 0.9881 - val_accuracy: 0.5333\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9446 - accuracy: 0.6583 - val_loss: 0.9858 - val_accuracy: 0.5667\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.9423 - accuracy: 0.6583 - val_loss: 0.9835 - val_accuracy: 0.5667\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.9398 - accuracy: 0.6667 - val_loss: 0.9812 - val_accuracy: 0.5667\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9373 - accuracy: 0.6750 - val_loss: 0.9789 - val_accuracy: 0.5667\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.9349 - accuracy: 0.6750 - val_loss: 0.9766 - val_accuracy: 0.6333\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9324 - accuracy: 0.6750 - val_loss: 0.9743 - val_accuracy: 0.6333\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 0.9299 - accuracy: 0.6750 - val_loss: 0.9718 - val_accuracy: 0.6333\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.9274 - accuracy: 0.6750 - val_loss: 0.9694 - val_accuracy: 0.6333\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9249 - accuracy: 0.6750 - val_loss: 0.9670 - val_accuracy: 0.6333\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.9225 - accuracy: 0.6833 - val_loss: 0.9645 - val_accuracy: 0.6333\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.9199 - accuracy: 0.6833 - val_loss: 0.9623 - val_accuracy: 0.6333\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.9175 - accuracy: 0.6833 - val_loss: 0.9601 - val_accuracy: 0.6333\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9149 - accuracy: 0.6917 - val_loss: 0.9578 - val_accuracy: 0.6333\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 0.9124 - accuracy: 0.7000 - val_loss: 0.9554 - val_accuracy: 0.6333\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.9100 - accuracy: 0.7000 - val_loss: 0.9531 - val_accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.9075 - accuracy: 0.7000 - val_loss: 0.9508 - val_accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.9050 - accuracy: 0.7000 - val_loss: 0.9485 - val_accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.9025 - accuracy: 0.7000 - val_loss: 0.9461 - val_accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.9002 - accuracy: 0.7000 - val_loss: 0.9440 - val_accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 224us/sample - loss: 0.8976 - accuracy: 0.7000 - val_loss: 0.9416 - val_accuracy: 0.6333\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.8952 - accuracy: 0.7000 - val_loss: 0.9392 - val_accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8928 - accuracy: 0.7000 - val_loss: 0.9369 - val_accuracy: 0.6333\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8903 - accuracy: 0.7000 - val_loss: 0.9345 - val_accuracy: 0.6333\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.8879 - accuracy: 0.7083 - val_loss: 0.9323 - val_accuracy: 0.6333\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.8854 - accuracy: 0.7083 - val_loss: 0.9297 - val_accuracy: 0.6333\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8830 - accuracy: 0.7083 - val_loss: 0.9272 - val_accuracy: 0.6333\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 196us/sample - loss: 0.8806 - accuracy: 0.7083 - val_loss: 0.9249 - val_accuracy: 0.6333\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.8782 - accuracy: 0.7083 - val_loss: 0.9226 - val_accuracy: 0.6333\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8758 - accuracy: 0.7083 - val_loss: 0.9203 - val_accuracy: 0.6333\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.8734 - accuracy: 0.7083 - val_loss: 0.9181 - val_accuracy: 0.6333\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.8710 - accuracy: 0.7083 - val_loss: 0.9155 - val_accuracy: 0.6333\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8686 - accuracy: 0.7083 - val_loss: 0.9132 - val_accuracy: 0.6333\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 207us/sample - loss: 0.8662 - accuracy: 0.7083 - val_loss: 0.9108 - val_accuracy: 0.6333\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8637 - accuracy: 0.7083 - val_loss: 0.9086 - val_accuracy: 0.6333\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8614 - accuracy: 0.7083 - val_loss: 0.9064 - val_accuracy: 0.6333\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8590 - accuracy: 0.7083 - val_loss: 0.9042 - val_accuracy: 0.6333\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8566 - accuracy: 0.7083 - val_loss: 0.9018 - val_accuracy: 0.6333\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8542 - accuracy: 0.7083 - val_loss: 0.8996 - val_accuracy: 0.6333\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.8519 - accuracy: 0.7083 - val_loss: 0.8974 - val_accuracy: 0.6333\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.8496 - accuracy: 0.7083 - val_loss: 0.8953 - val_accuracy: 0.6333\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8471 - accuracy: 0.7083 - val_loss: 0.8930 - val_accuracy: 0.6333\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8448 - accuracy: 0.7083 - val_loss: 0.8907 - val_accuracy: 0.6333\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.8425 - accuracy: 0.7083 - val_loss: 0.8882 - val_accuracy: 0.6333\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.8402 - accuracy: 0.7083 - val_loss: 0.8860 - val_accuracy: 0.6333\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.8378 - accuracy: 0.7083 - val_loss: 0.8837 - val_accuracy: 0.6333\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8355 - accuracy: 0.7083 - val_loss: 0.8815 - val_accuracy: 0.6333\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.8332 - accuracy: 0.7083 - val_loss: 0.8790 - val_accuracy: 0.6333\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 165us/sample - loss: 0.8308 - accuracy: 0.7083 - val_loss: 0.8768 - val_accuracy: 0.6333\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8285 - accuracy: 0.7083 - val_loss: 0.8746 - val_accuracy: 0.6333\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 197us/sample - loss: 0.8263 - accuracy: 0.7083 - val_loss: 0.8722 - val_accuracy: 0.6333\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8239 - accuracy: 0.7167 - val_loss: 0.8698 - val_accuracy: 0.6333\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.8217 - accuracy: 0.7250 - val_loss: 0.8676 - val_accuracy: 0.6333\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.8193 - accuracy: 0.7250 - val_loss: 0.8654 - val_accuracy: 0.6333\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8170 - accuracy: 0.7250 - val_loss: 0.8631 - val_accuracy: 0.6333\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.8148 - accuracy: 0.7250 - val_loss: 0.8609 - val_accuracy: 0.6333\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 216us/sample - loss: 0.8126 - accuracy: 0.7250 - val_loss: 0.8588 - val_accuracy: 0.6333\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.8103 - accuracy: 0.7250 - val_loss: 0.8564 - val_accuracy: 0.6333\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.8082 - accuracy: 0.7250 - val_loss: 0.8539 - val_accuracy: 0.6333\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.8058 - accuracy: 0.7250 - val_loss: 0.8517 - val_accuracy: 0.6333\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.8036 - accuracy: 0.7250 - val_loss: 0.8497 - val_accuracy: 0.6333\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.8013 - accuracy: 0.7250 - val_loss: 0.8475 - val_accuracy: 0.6333\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7992 - accuracy: 0.7250 - val_loss: 0.8451 - val_accuracy: 0.6333\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7969 - accuracy: 0.7250 - val_loss: 0.8430 - val_accuracy: 0.6333\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7947 - accuracy: 0.7250 - val_loss: 0.8406 - val_accuracy: 0.6333\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.7925 - accuracy: 0.7250 - val_loss: 0.8385 - val_accuracy: 0.6333\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.7903 - accuracy: 0.7250 - val_loss: 0.8362 - val_accuracy: 0.6333\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 232us/sample - loss: 0.7881 - accuracy: 0.7250 - val_loss: 0.8339 - val_accuracy: 0.6333\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.7859 - accuracy: 0.7250 - val_loss: 0.8316 - val_accuracy: 0.6333\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.7838 - accuracy: 0.7250 - val_loss: 0.8294 - val_accuracy: 0.6333\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7815 - accuracy: 0.7250 - val_loss: 0.8271 - val_accuracy: 0.6667\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7793 - accuracy: 0.7250 - val_loss: 0.8247 - val_accuracy: 0.6667\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7772 - accuracy: 0.7250 - val_loss: 0.8224 - val_accuracy: 0.6667\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.7750 - accuracy: 0.7250 - val_loss: 0.8201 - val_accuracy: 0.6667\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 230us/sample - loss: 0.7729 - accuracy: 0.7250 - val_loss: 0.8179 - val_accuracy: 0.6667\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.7707 - accuracy: 0.7250 - val_loss: 0.8156 - val_accuracy: 0.6667\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7686 - accuracy: 0.7250 - val_loss: 0.8133 - val_accuracy: 0.6667\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.7665 - accuracy: 0.7250 - val_loss: 0.8110 - val_accuracy: 0.6667\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7644 - accuracy: 0.7250 - val_loss: 0.8088 - val_accuracy: 0.6667\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.7623 - accuracy: 0.7250 - val_loss: 0.8067 - val_accuracy: 0.6667\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.7601 - accuracy: 0.7250 - val_loss: 0.8046 - val_accuracy: 0.6667\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.7581 - accuracy: 0.7250 - val_loss: 0.8022 - val_accuracy: 0.6667\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.7561 - accuracy: 0.7250 - val_loss: 0.8003 - val_accuracy: 0.6667\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.7539 - accuracy: 0.7250 - val_loss: 0.7979 - val_accuracy: 0.6667\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7518 - accuracy: 0.7250 - val_loss: 0.7957 - val_accuracy: 0.6667\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7498 - accuracy: 0.7250 - val_loss: 0.7932 - val_accuracy: 0.6667\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.7477 - accuracy: 0.7250 - val_loss: 0.7909 - val_accuracy: 0.6667\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7456 - accuracy: 0.7333 - val_loss: 0.7887 - val_accuracy: 0.7000\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.7436 - accuracy: 0.7333 - val_loss: 0.7866 - val_accuracy: 0.7000\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.7416 - accuracy: 0.7333 - val_loss: 0.7846 - val_accuracy: 0.7000\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.7396 - accuracy: 0.7333 - val_loss: 0.7824 - val_accuracy: 0.7000\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7375 - accuracy: 0.7333 - val_loss: 0.7803 - val_accuracy: 0.7000\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.7355 - accuracy: 0.7333 - val_loss: 0.7781 - val_accuracy: 0.7000\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7335 - accuracy: 0.7333 - val_loss: 0.7761 - val_accuracy: 0.7000\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 191us/sample - loss: 0.7315 - accuracy: 0.7333 - val_loss: 0.7741 - val_accuracy: 0.7000\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.7294 - accuracy: 0.7333 - val_loss: 0.7719 - val_accuracy: 0.7000\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 215us/sample - loss: 0.7274 - accuracy: 0.7333 - val_loss: 0.7697 - val_accuracy: 0.7000\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.7255 - accuracy: 0.7333 - val_loss: 0.7677 - val_accuracy: 0.7000\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7235 - accuracy: 0.7333 - val_loss: 0.7656 - val_accuracy: 0.7000\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.7215 - accuracy: 0.7333 - val_loss: 0.7635 - val_accuracy: 0.7000\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.7196 - accuracy: 0.7333 - val_loss: 0.7616 - val_accuracy: 0.7000\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.7176 - accuracy: 0.7333 - val_loss: 0.7595 - val_accuracy: 0.7000\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 308us/sample - loss: 0.7157 - accuracy: 0.7333 - val_loss: 0.7575 - val_accuracy: 0.7000\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7137 - accuracy: 0.7333 - val_loss: 0.7555 - val_accuracy: 0.7000\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.7118 - accuracy: 0.7333 - val_loss: 0.7535 - val_accuracy: 0.7000\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7098 - accuracy: 0.7333 - val_loss: 0.7513 - val_accuracy: 0.7000\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 193us/sample - loss: 0.7079 - accuracy: 0.7333 - val_loss: 0.7493 - val_accuracy: 0.7000\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 0.7060 - accuracy: 0.7333 - val_loss: 0.7472 - val_accuracy: 0.7000\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7040 - accuracy: 0.7333 - val_loss: 0.7450 - val_accuracy: 0.7000\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.7020 - accuracy: 0.7333 - val_loss: 0.7429 - val_accuracy: 0.7000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.7001 - accuracy: 0.7333 - val_loss: 0.7409 - val_accuracy: 0.7000\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 375us/sample - loss: 0.6981 - accuracy: 0.7333 - val_loss: 0.7389 - val_accuracy: 0.7000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 0.6962 - accuracy: 0.7333 - val_loss: 0.7370 - val_accuracy: 0.7000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6941 - accuracy: 0.7333 - val_loss: 0.7350 - val_accuracy: 0.7000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 201us/sample - loss: 0.6920 - accuracy: 0.7333 - val_loss: 0.7329 - val_accuracy: 0.7000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.6902 - accuracy: 0.7333 - val_loss: 0.7309 - val_accuracy: 0.7333\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.6878 - accuracy: 0.7417 - val_loss: 0.7293 - val_accuracy: 0.7333\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.6854 - accuracy: 0.7500 - val_loss: 0.7273 - val_accuracy: 0.7333\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.6831 - accuracy: 0.7500 - val_loss: 0.7255 - val_accuracy: 0.7333\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.6807 - accuracy: 0.7500 - val_loss: 0.7236 - val_accuracy: 0.7000\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6777 - accuracy: 0.7500 - val_loss: 0.7222 - val_accuracy: 0.6667\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 692us/sample - loss: 0.6749 - accuracy: 0.7667 - val_loss: 0.7208 - val_accuracy: 0.6667\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 417us/sample - loss: 0.6729 - accuracy: 0.7667 - val_loss: 0.7193 - val_accuracy: 0.6667\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.6705 - accuracy: 0.7667 - val_loss: 0.7174 - val_accuracy: 0.6667\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6681 - accuracy: 0.7667 - val_loss: 0.7140 - val_accuracy: 0.6667\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.6654 - accuracy: 0.7750 - val_loss: 0.7112 - val_accuracy: 0.6667\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.6632 - accuracy: 0.7750 - val_loss: 0.7081 - val_accuracy: 0.6667\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.6605 - accuracy: 0.7750 - val_loss: 0.7057 - val_accuracy: 0.6667\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.6582 - accuracy: 0.7750 - val_loss: 0.7030 - val_accuracy: 0.7000\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.6558 - accuracy: 0.7750 - val_loss: 0.7007 - val_accuracy: 0.7000\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.6534 - accuracy: 0.7750 - val_loss: 0.6980 - val_accuracy: 0.7000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.6511 - accuracy: 0.7750 - val_loss: 0.6955 - val_accuracy: 0.7000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.6487 - accuracy: 0.7750 - val_loss: 0.6934 - val_accuracy: 0.7000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.6465 - accuracy: 0.7750 - val_loss: 0.6906 - val_accuracy: 0.7000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.6439 - accuracy: 0.7750 - val_loss: 0.6882 - val_accuracy: 0.7000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6417 - accuracy: 0.7750 - val_loss: 0.6858 - val_accuracy: 0.7000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6391 - accuracy: 0.7750 - val_loss: 0.6837 - val_accuracy: 0.7000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.6368 - accuracy: 0.7750 - val_loss: 0.6817 - val_accuracy: 0.7333\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.6345 - accuracy: 0.7750 - val_loss: 0.6795 - val_accuracy: 0.7333\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.6322 - accuracy: 0.7750 - val_loss: 0.6770 - val_accuracy: 0.7333\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 209us/sample - loss: 0.6299 - accuracy: 0.7750 - val_loss: 0.6746 - val_accuracy: 0.7333\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.6277 - accuracy: 0.7750 - val_loss: 0.6720 - val_accuracy: 0.7667\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.6254 - accuracy: 0.7833 - val_loss: 0.6695 - val_accuracy: 0.7667\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 458us/sample - loss: 0.6231 - accuracy: 0.7833 - val_loss: 0.6670 - val_accuracy: 0.7667\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.6208 - accuracy: 0.7833 - val_loss: 0.6648 - val_accuracy: 0.8000\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.6186 - accuracy: 0.7833 - val_loss: 0.6624 - val_accuracy: 0.8000\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.6162 - accuracy: 0.7833 - val_loss: 0.6600 - val_accuracy: 0.8000\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.6141 - accuracy: 0.7833 - val_loss: 0.6579 - val_accuracy: 0.8000\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 234us/sample - loss: 0.6119 - accuracy: 0.7833 - val_loss: 0.6553 - val_accuracy: 0.8000\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.6096 - accuracy: 0.7833 - val_loss: 0.6525 - val_accuracy: 0.8000\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.6073 - accuracy: 0.8000 - val_loss: 0.6499 - val_accuracy: 0.8333\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 208us/sample - loss: 0.6053 - accuracy: 0.8083 - val_loss: 0.6474 - val_accuracy: 0.8333\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.6031 - accuracy: 0.8083 - val_loss: 0.6450 - val_accuracy: 0.8333\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.6009 - accuracy: 0.8083 - val_loss: 0.6427 - val_accuracy: 0.8333\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.5988 - accuracy: 0.8083 - val_loss: 0.6403 - val_accuracy: 0.8333\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.5966 - accuracy: 0.8083 - val_loss: 0.6382 - val_accuracy: 0.8333\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.5945 - accuracy: 0.8167 - val_loss: 0.6359 - val_accuracy: 0.8333\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.5924 - accuracy: 0.8167 - val_loss: 0.6335 - val_accuracy: 0.8333\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.5903 - accuracy: 0.8167 - val_loss: 0.6312 - val_accuracy: 0.8333\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 221us/sample - loss: 0.5882 - accuracy: 0.8167 - val_loss: 0.6287 - val_accuracy: 0.8333\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 194us/sample - loss: 0.5861 - accuracy: 0.8250 - val_loss: 0.6265 - val_accuracy: 0.8333\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5842 - accuracy: 0.8417 - val_loss: 0.6241 - val_accuracy: 0.8333\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5819 - accuracy: 0.8417 - val_loss: 0.6219 - val_accuracy: 0.8333\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5799 - accuracy: 0.8417 - val_loss: 0.6196 - val_accuracy: 0.8333\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.5779 - accuracy: 0.8417 - val_loss: 0.6173 - val_accuracy: 0.8333\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.5760 - accuracy: 0.8417 - val_loss: 0.6150 - val_accuracy: 0.8667\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.5738 - accuracy: 0.8417 - val_loss: 0.6129 - val_accuracy: 0.8667\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5718 - accuracy: 0.8417 - val_loss: 0.6108 - val_accuracy: 0.8667\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5698 - accuracy: 0.8417 - val_loss: 0.6086 - val_accuracy: 0.8667\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5678 - accuracy: 0.8417 - val_loss: 0.6064 - val_accuracy: 0.8667\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.81 - 0s 241us/sample - loss: 0.5658 - accuracy: 0.8417 - val_loss: 0.6041 - val_accuracy: 0.8667\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.5638 - accuracy: 0.8583 - val_loss: 0.6019 - val_accuracy: 0.9000\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5618 - accuracy: 0.8583 - val_loss: 0.5997 - val_accuracy: 0.9000\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.5599 - accuracy: 0.8583 - val_loss: 0.5977 - val_accuracy: 0.9000\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 192us/sample - loss: 0.5579 - accuracy: 0.8583 - val_loss: 0.5954 - val_accuracy: 0.9000\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.5559 - accuracy: 0.8583 - val_loss: 0.5932 - val_accuracy: 0.9333\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.5544 - accuracy: 0.8583 - val_loss: 0.5908 - val_accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.5522 - accuracy: 0.8667 - val_loss: 0.5887 - val_accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.5501 - accuracy: 0.8667 - val_loss: 0.5866 - val_accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5483 - accuracy: 0.8667 - val_loss: 0.5846 - val_accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5466 - accuracy: 0.8667 - val_loss: 0.5826 - val_accuracy: 0.9667\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5445 - accuracy: 0.8667 - val_loss: 0.5805 - val_accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5426 - accuracy: 0.8750 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.5412 - accuracy: 0.8750 - val_loss: 0.5761 - val_accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5390 - accuracy: 0.8750 - val_loss: 0.5741 - val_accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 258us/sample - loss: 0.5371 - accuracy: 0.8750 - val_loss: 0.5721 - val_accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5354 - accuracy: 0.8750 - val_loss: 0.5702 - val_accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5336 - accuracy: 0.8750 - val_loss: 0.5681 - val_accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5317 - accuracy: 0.8750 - val_loss: 0.5661 - val_accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.5299 - accuracy: 0.8750 - val_loss: 0.5643 - val_accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 283us/sample - loss: 0.5283 - accuracy: 0.8750 - val_loss: 0.5622 - val_accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 275us/sample - loss: 0.5263 - accuracy: 0.8833 - val_loss: 0.5603 - val_accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.5246 - accuracy: 0.8750 - val_loss: 0.5584 - val_accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5229 - accuracy: 0.8750 - val_loss: 0.5566 - val_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.93 - 0s 192us/sample - loss: 0.5212 - accuracy: 0.8750 - val_loss: 0.5547 - val_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.5194 - accuracy: 0.8750 - val_loss: 0.5527 - val_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.5178 - accuracy: 0.8833 - val_loss: 0.5507 - val_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.5160 - accuracy: 0.8833 - val_loss: 0.5489 - val_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.5145 - accuracy: 0.8833 - val_loss: 0.5471 - val_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5125 - accuracy: 0.8917 - val_loss: 0.5452 - val_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.5108 - accuracy: 0.8917 - val_loss: 0.5433 - val_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.5094 - accuracy: 0.9083 - val_loss: 0.5415 - val_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.5075 - accuracy: 0.9083 - val_loss: 0.5396 - val_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 175us/sample - loss: 0.5062 - accuracy: 0.8917 - val_loss: 0.5377 - val_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.5043 - accuracy: 0.8917 - val_loss: 0.5359 - val_accuracy: 1.0000\n",
      "Epoch 275/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 208us/sample - loss: 0.5025 - accuracy: 0.9000 - val_loss: 0.5341 - val_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.5009 - accuracy: 0.9083 - val_loss: 0.5323 - val_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.4992 - accuracy: 0.9167 - val_loss: 0.5306 - val_accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.4977 - accuracy: 0.9167 - val_loss: 0.5288 - val_accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.4959 - accuracy: 0.9167 - val_loss: 0.5271 - val_accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 185us/sample - loss: 0.4944 - accuracy: 0.9250 - val_loss: 0.5254 - val_accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 184us/sample - loss: 0.4927 - accuracy: 0.9250 - val_loss: 0.5237 - val_accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.4912 - accuracy: 0.9250 - val_loss: 0.5220 - val_accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 250us/sample - loss: 0.4895 - accuracy: 0.9250 - val_loss: 0.5202 - val_accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.4879 - accuracy: 0.9250 - val_loss: 0.5184 - val_accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.4863 - accuracy: 0.9250 - val_loss: 0.5167 - val_accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 208us/sample - loss: 0.4848 - accuracy: 0.9250 - val_loss: 0.5149 - val_accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 180us/sample - loss: 0.4834 - accuracy: 0.9250 - val_loss: 0.5131 - val_accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.4816 - accuracy: 0.9250 - val_loss: 0.5114 - val_accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4801 - accuracy: 0.9250 - val_loss: 0.5096 - val_accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 267us/sample - loss: 0.4786 - accuracy: 0.9250 - val_loss: 0.5081 - val_accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4773 - accuracy: 0.9250 - val_loss: 0.5066 - val_accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4816 - accuracy: 0.90 - 0s 225us/sample - loss: 0.4754 - accuracy: 0.9250 - val_loss: 0.5049 - val_accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 233us/sample - loss: 0.4738 - accuracy: 0.9250 - val_loss: 0.5032 - val_accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 242us/sample - loss: 0.4723 - accuracy: 0.9250 - val_loss: 0.5014 - val_accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 225us/sample - loss: 0.4708 - accuracy: 0.9250 - val_loss: 0.4996 - val_accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.4694 - accuracy: 0.9250 - val_loss: 0.4978 - val_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.4679 - accuracy: 0.9250 - val_loss: 0.4961 - val_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 0.4663 - accuracy: 0.9250 - val_loss: 0.4945 - val_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 200us/sample - loss: 0.4649 - accuracy: 0.9250 - val_loss: 0.4930 - val_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 217us/sample - loss: 0.4634 - accuracy: 0.9333 - val_loss: 0.4913 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b43f434e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop=EarlyStopping(patience=10)\n",
    "\n",
    "model.fit(x=scaled_X_train, y=y_train, epochs=300, validation_data=[scaled_X_test, y_test], callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "parallel-music",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b43f71ddc8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics=pd.DataFrame(model.history.history)\n",
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "encouraging-president",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b441bc2108>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "understanding-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4912974536418915, 1.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "million-keeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 0s 3ms/sample - loss: 1.2284 - accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 1.2179 - accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.2081 - accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.1990 - accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.1896 - accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.1814 - accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.1733 - accuracy: 0.0067\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.1649 - accuracy: 0.0067\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.1574 - accuracy: 0.0200\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.1511 - accuracy: 0.0333\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.1437 - accuracy: 0.0667\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.1369 - accuracy: 0.1267\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.1317 - accuracy: 0.1933\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 1.1252 - accuracy: 0.3067\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.1195 - accuracy: 0.2867\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.1141 - accuracy: 0.3000\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.1084 - accuracy: 0.3067\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.1034 - accuracy: 0.2933\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0985 - accuracy: 0.3000\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.0938 - accuracy: 0.3067\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0897 - accuracy: 0.3133\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.0844 - accuracy: 0.3067\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0801 - accuracy: 0.3133\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0758 - accuracy: 0.3133\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0718 - accuracy: 0.3133\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0675 - accuracy: 0.3333\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0632 - accuracy: 0.3333\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0592 - accuracy: 0.3400\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0552 - accuracy: 0.3400\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0512 - accuracy: 0.3467\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 1.0473 - accuracy: 0.3467\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0434 - accuracy: 0.3467\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 1.0396 - accuracy: 0.3467\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 1.0358 - accuracy: 0.3533\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0319 - accuracy: 0.3533\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0283 - accuracy: 0.3533\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 1.0245 - accuracy: 0.3800\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0207 - accuracy: 0.4733\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0172 - accuracy: 0.4800\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0135 - accuracy: 0.5267\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 1.0099 - accuracy: 0.5533\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0063 - accuracy: 0.5867\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 1.0027 - accuracy: 0.6067\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9992 - accuracy: 0.6067\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9957 - accuracy: 0.6067\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9923 - accuracy: 0.6333\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 0.9889 - accuracy: 0.6400\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9855 - accuracy: 0.6400\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9822 - accuracy: 0.6467\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.9790 - accuracy: 0.6533\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.9757 - accuracy: 0.6533\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.9726 - accuracy: 0.6533\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.9693 - accuracy: 0.6533\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.9661 - accuracy: 0.6533\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.9631 - accuracy: 0.6600\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9599 - accuracy: 0.6600\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.9568 - accuracy: 0.6667\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.9538 - accuracy: 0.6667\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9508 - accuracy: 0.6667\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9478 - accuracy: 0.6733\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9447 - accuracy: 0.6733\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9418 - accuracy: 0.6733\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9389 - accuracy: 0.6733\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9359 - accuracy: 0.6733\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9329 - accuracy: 0.6733\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9300 - accuracy: 0.6733\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.9271 - accuracy: 0.6733\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9243 - accuracy: 0.6733\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.9214 - accuracy: 0.6733\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9186 - accuracy: 0.6733\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9157 - accuracy: 0.6733\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9130 - accuracy: 0.6733\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9100 - accuracy: 0.6733\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9071 - accuracy: 0.6733\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9043 - accuracy: 0.6733\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9014 - accuracy: 0.6733\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8986 - accuracy: 0.6733\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8958 - accuracy: 0.6733\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8930 - accuracy: 0.6733\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.8902 - accuracy: 0.6733\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8874 - accuracy: 0.6733\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8848 - accuracy: 0.6733\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8819 - accuracy: 0.6733\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.8791 - accuracy: 0.6733\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.8764 - accuracy: 0.6733\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.8735 - accuracy: 0.6733\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8708 - accuracy: 0.6733\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8681 - accuracy: 0.6733\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8653 - accuracy: 0.6733\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8626 - accuracy: 0.6800\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8599 - accuracy: 0.6800\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.8571 - accuracy: 0.6800\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8544 - accuracy: 0.6800\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8517 - accuracy: 0.6800\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8490 - accuracy: 0.6800\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.8463 - accuracy: 0.6800\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8436 - accuracy: 0.6800\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8409 - accuracy: 0.6800\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8383 - accuracy: 0.6800\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8355 - accuracy: 0.6800\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8329 - accuracy: 0.6800\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8302 - accuracy: 0.6800\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8275 - accuracy: 0.6800\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.8249 - accuracy: 0.6800\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8223 - accuracy: 0.6800\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8196 - accuracy: 0.6800\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8170 - accuracy: 0.6800\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8144 - accuracy: 0.6800\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8118 - accuracy: 0.6867\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8091 - accuracy: 0.6867\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8067 - accuracy: 0.6867\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.8039 - accuracy: 0.6933\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.8014 - accuracy: 0.6933\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7988 - accuracy: 0.6933\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7962 - accuracy: 0.7000\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7937 - accuracy: 0.7000\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7911 - accuracy: 0.7067\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7887 - accuracy: 0.7067\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7860 - accuracy: 0.7067\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7835 - accuracy: 0.7067\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7810 - accuracy: 0.7067\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7784 - accuracy: 0.7133\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7759 - accuracy: 0.7133\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7669 - accuracy: 0.75 - 0s 73us/sample - loss: 0.7734 - accuracy: 0.7200\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7709 - accuracy: 0.7267\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7685 - accuracy: 0.7267\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7659 - accuracy: 0.7267\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7635 - accuracy: 0.7267\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.7610 - accuracy: 0.7267\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7585 - accuracy: 0.7267\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7561 - accuracy: 0.7267\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7537 - accuracy: 0.7267\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7512 - accuracy: 0.7333\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7488 - accuracy: 0.7333\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7464 - accuracy: 0.7333\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7439 - accuracy: 0.7333\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.7599 - accuracy: 0.59 - 0s 73us/sample - loss: 0.7416 - accuracy: 0.7333\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7392 - accuracy: 0.7400\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7368 - accuracy: 0.7400\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7345 - accuracy: 0.7467\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7322 - accuracy: 0.7467\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7298 - accuracy: 0.7400\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7275 - accuracy: 0.7400\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.7252 - accuracy: 0.7400\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7230 - accuracy: 0.7400\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7207 - accuracy: 0.7467\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7184 - accuracy: 0.7467\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7162 - accuracy: 0.7400\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7140 - accuracy: 0.7467\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7118 - accuracy: 0.7467\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7096 - accuracy: 0.7467\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7073 - accuracy: 0.7467\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.7052 - accuracy: 0.7467\n",
      "Epoch 154/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7031 - accuracy: 0.7467\n",
      "Epoch 155/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.7011 - accuracy: 0.7467\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6991 - accuracy: 0.7533\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6968 - accuracy: 0.7533\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6948 - accuracy: 0.7600\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6925 - accuracy: 0.7600\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6907 - accuracy: 0.7600\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6886 - accuracy: 0.7600\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6866 - accuracy: 0.7600\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6846 - accuracy: 0.7600\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6827 - accuracy: 0.7600\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6807 - accuracy: 0.7600\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6788 - accuracy: 0.7600\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6769 - accuracy: 0.7600\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6750 - accuracy: 0.7600\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6731 - accuracy: 0.7600\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6712 - accuracy: 0.7600\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6694 - accuracy: 0.7600\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6676 - accuracy: 0.7600\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6657 - accuracy: 0.7600\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6640 - accuracy: 0.7667\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6621 - accuracy: 0.7667\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6604 - accuracy: 0.7733\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6586 - accuracy: 0.7733\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6568 - accuracy: 0.7800\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6552 - accuracy: 0.7800\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6535 - accuracy: 0.7800\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6519 - accuracy: 0.7800\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6500 - accuracy: 0.7800\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6483 - accuracy: 0.7800\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6467 - accuracy: 0.7800\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6451 - accuracy: 0.7800\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6434 - accuracy: 0.7667\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6418 - accuracy: 0.7667\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6402 - accuracy: 0.7667\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6386 - accuracy: 0.7733\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.6370 - accuracy: 0.7733\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6355 - accuracy: 0.7733\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 133us/sample - loss: 0.6338 - accuracy: 0.7733\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6322 - accuracy: 0.7733\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6307 - accuracy: 0.7800\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.6294 - accuracy: 0.7800\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.6276 - accuracy: 0.7800\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.6262 - accuracy: 0.7800\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.6247 - accuracy: 0.7800\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6232 - accuracy: 0.7800\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6218 - accuracy: 0.7800\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6202 - accuracy: 0.7800\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6189 - accuracy: 0.7800\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6172 - accuracy: 0.7800\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6158 - accuracy: 0.7800\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6144 - accuracy: 0.7800\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6129 - accuracy: 0.7800\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6116 - accuracy: 0.7800\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6103 - accuracy: 0.7800\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.6088 - accuracy: 0.7800\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6074 - accuracy: 0.7800\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6060 - accuracy: 0.7800\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6045 - accuracy: 0.7800\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.6032 - accuracy: 0.7800\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6018 - accuracy: 0.7800\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.6005 - accuracy: 0.7800\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5990 - accuracy: 0.7867\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5981 - accuracy: 0.7800\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5964 - accuracy: 0.7800\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5950 - accuracy: 0.7800\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5937 - accuracy: 0.7933\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5925 - accuracy: 0.7867\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5910 - accuracy: 0.7867\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5897 - accuracy: 0.7933\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5884 - accuracy: 0.7933\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5872 - accuracy: 0.7933\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5859 - accuracy: 0.7933\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5845 - accuracy: 0.7933\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5833 - accuracy: 0.7933\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5821 - accuracy: 0.7933\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5807 - accuracy: 0.7933\n",
      "Epoch 231/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5798 - accuracy: 0.8067\n",
      "Epoch 232/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5783 - accuracy: 0.8133\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5770 - accuracy: 0.8133\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5757 - accuracy: 0.8067\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5745 - accuracy: 0.8067\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5736 - accuracy: 0.8133\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5721 - accuracy: 0.8133\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5709 - accuracy: 0.8133\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5696 - accuracy: 0.8133\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5684 - accuracy: 0.8133\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5672 - accuracy: 0.8200\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5661 - accuracy: 0.8200\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5648 - accuracy: 0.8267\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5636 - accuracy: 0.8267\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5625 - accuracy: 0.8200\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5614 - accuracy: 0.8267\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5601 - accuracy: 0.8267\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 107us/sample - loss: 0.5591 - accuracy: 0.8333\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5579 - accuracy: 0.8333\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5568 - accuracy: 0.8333\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5556 - accuracy: 0.8267\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5545 - accuracy: 0.8267\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5534 - accuracy: 0.8333\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5523 - accuracy: 0.8333\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.5513 - accuracy: 0.8333\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5502 - accuracy: 0.8267\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5491 - accuracy: 0.8267\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5479 - accuracy: 0.8267\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5468 - accuracy: 0.8267\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5458 - accuracy: 0.8333\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5446 - accuracy: 0.8333\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5436 - accuracy: 0.8333\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5426 - accuracy: 0.8467\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5416 - accuracy: 0.8333\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5404 - accuracy: 0.8467\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5395 - accuracy: 0.8467\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5385 - accuracy: 0.8533\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5374 - accuracy: 0.8533\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5364 - accuracy: 0.8533\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5355 - accuracy: 0.8533\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5346 - accuracy: 0.8467\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5333 - accuracy: 0.8467\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5323 - accuracy: 0.8533\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5312 - accuracy: 0.8533\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5302 - accuracy: 0.8533\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5291 - accuracy: 0.8533\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5283 - accuracy: 0.8600\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5274 - accuracy: 0.8667\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5263 - accuracy: 0.8667\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5253 - accuracy: 0.8667\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.5246 - accuracy: 0.8600\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5234 - accuracy: 0.8667\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5224 - accuracy: 0.8667\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5218 - accuracy: 0.8667\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5205 - accuracy: 0.8667\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5195 - accuracy: 0.8667\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5186 - accuracy: 0.8667\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5176 - accuracy: 0.8667\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5167 - accuracy: 0.8600\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5158 - accuracy: 0.8533\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.5149 - accuracy: 0.8533\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5140 - accuracy: 0.8533\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.5130 - accuracy: 0.8533\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5121 - accuracy: 0.8533\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5112 - accuracy: 0.8533\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5103 - accuracy: 0.8533\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5095 - accuracy: 0.8533\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5085 - accuracy: 0.8533\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5076 - accuracy: 0.8667\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5067 - accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b441dbd288>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model for all data - phese 2, because accuracy on train data is 93%\n",
    "\n",
    "epochs=len(metrics)\n",
    "scaled_X=scaler.fit_transform(X)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=scaled_X, y=y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "metallic-distribution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_final_iris_scaler.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('my_final_iris_model.h5')\n",
    "\n",
    "\n",
    "import joblib\n",
    "joblib.dump(scaler, 'my_final_iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baking-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "flower_model=load_model('my_final_iris_model.h5')\n",
    "flower_scaler=joblib.load('my_final_iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-virus",
   "metadata": {},
   "source": [
    "## Model Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "rational-stuff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "protective-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example={\"sepal_length\":5.1,\n",
    "               \"sepal_width\":3.5, \n",
    "               \"petal_length\": 1.4,\n",
    "               \"petal_width\": 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "published-cologne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model, scaler, sample_json):\n",
    "    \n",
    "    sepal_length=sample_json['sepal_length']\n",
    "    sepal_width=sample_json['sepal_width']\n",
    "    petal_length=sample_json['petal_length']\n",
    "    petal_width=sample_json['petal_width']\n",
    "    \n",
    "    classes=np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower=[[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "    flower=scaler.transform(flower)\n",
    "    \n",
    "    class_ind=model.predict_classes(flower)[0] #to get only item of array which is class index\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "wound-elements",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model, flower_scaler, flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-lingerie",
   "metadata": {},
   "source": [
    "### CODE FOR DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "heard-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "\n",
    "flower_model=load_model('my_final_iris_model.h5')\n",
    "flower_scaler=joblib.load('my_final_iris_scaler.pkl')\n",
    "\n",
    "\n",
    "def return_prediction(model, scaler, sample_json):\n",
    "    \n",
    "    sepal_length=sample_json['sepal_length']\n",
    "    sepal_width=sample_json['sepal_width']\n",
    "    petal_length=sample_json['petal_length']\n",
    "    petal_width=sample_json['petal_width']\n",
    "    \n",
    "    classes=np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    flower=[[sepal_length, sepal_width, petal_length, petal_width]]\n",
    "    flower=scaler.transform(flower)\n",
    "    \n",
    "    class_ind=model.predict_classes(flower)[0] #to get only item of array which is class index\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-dispatch",
   "metadata": {},
   "source": [
    "## Flask API - Using Requests Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "horizontal-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cooked-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example={\"sepal_length\":5.1,\n",
    "               \"sepal_width\":3.5, \n",
    "               \"petal_length\": 1.4,\n",
    "               \"petal_width\": 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "departmental-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=requests.post(\"http://127.0.0.1:5000/api/flower\", json=flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acting-essence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "preliminary-affect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"setosa\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
